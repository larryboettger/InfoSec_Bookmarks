# AI Security Bookmarks

* [A New Attack Impacts Major AI Chatbots—and No One Knows How to Stop It](https://www.wired.com/story/ai-adversarial-attacks/)

* [Google Launches Red Team to Secure AI Systems Against Attacks](https://securityboulevard.com/2023/07/google-launches-red-team-to-secure-ai-systems-against-attacks/)

* [Ethical Hackers Reveal How They Use Generative AI](https://www.infosecurity-magazine.com/news/ethical-hackers-generative-ai/)

* [NIST Launches Generative AI Working Group](https://www.darkreading.com/dr-tech/nist-launches-generative-ai-working-group)

* [Owasp Top 10 for LLMs 2023 v05](https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v05.pdf)

* [A Golden Age of AI ¦ or Security Threats?](https://www.darkreading.com/vulnerabilities-threats/a-golden-age-of-ai-or-security-threats-)

* [AI Dominates RSA as Excitement and Questions Surround its Potential in Cybersecurity Tooling](https://www.infosecurity-magazine.com/news/ai-dominates-rsa/)

* [The Hacking of ChatGPT Is Just Getting Started](https://www.wired.com/story/chatgpt-jailbreak-generative-ai-hacking/)

* [Watch Out for These Generative AI and ChatGPT Cybersecurity Risks](https://itsecuritywire.com/featured/generative-ai-and-chatgpt-cybersecurity-risks/)

* [Announcing Arthur Shield: The First Firewall for LLMs](https://www.arthur.ai/blog/announcing-arthur-shield-the-first-firewall-for-llms?utm_source=organicsocial&utm_medium=twitter&utm_campaign=shield)

* [Google Launches Framework to Secure Generative AI](https://www.infosecurity-magazine.com/news/google-framework-secure-generative/)

* [CDEI publishes portfolio of AI assurance techniques | Computer Weekly](https://www.computerweekly.com/news/366539654/CDEI-publishes-portfolio-of-AI-assurance-techniques)

* [The opportunities and risks of ChatGPT in cybersecurity](https://securityboulevard.com/2023/06/the-opportunities-and-risks-of-chatgpt-in-cybersecurity/)

* [Navigating artificial intelligence: Red flags to watch out for](https://www.computerweekly.com/news/366537934/Navigating-artificial-intelligence-Red-flags-to-watch-out-for)

* [New ChatGPT Attack Technique Spreads Malicious Packages](https://www.infosecurity-magazine.com/news/chatgpt-spreads-malicious-packages/)

* [CySecurity News - Latest Information Security and Hacking Incidents: The Security Hole: Prompt Injection Attack in ChatGPT and Bing Maker](https://www.cysecurity.news/2023/05/the-security-hole-prompt-injection.html?utm_source=dlvr.it&utm_medium=twitter)

* [DeepSpaceHarbor/Awesome-AI-Security](https://github.com/DeepSpaceHarbor/Awesome-AI-Security)

* [Phishing campaign targets ChatGPT users - Help Net Security](https://www.helpnetsecurity.com/2023/05/25/chatgpt-phishing/)

* [Pen Testers Need to Hack AI, but Also Question Its Existence](https://www.darkreading.com/remote-workforce/pentesters-need-to-hack-ai-question-its-existence)

* [Phishing Attacks Surge as Threat Actors Leverage New AI Tools](https://www.infosecurity-magazine.com/news/phishing-surge-threat-actors-ai/)

* [AI tools like ChatGPT expected to fuel BEC attacks - Help Net Security](https://www.helpnetsecurity.com/2023/04/17/bec-attacks-language-attack-vector/)

* [Criminal Uses for ChatGPT: A Versatile New Tool for Hackers](https://securityboulevard.com/2023/04/criminal-uses-for-chatgpt-a-versatile-new-tool-for-hackers/)

* [The New Risks ChatGPT Poses to Cybersecurity](https://hbr.org/2023/04/the-new-risks-chatgpt-poses-to-cybersecurity)

* [Hackers Exploit Generative AI to Spread RedLine Stealer MaaS](https://securityboulevard.com/2023/04/hackers-exploit-generative-ai-to-spread-redline-stealer-maas/)

* [AI Experts: Account for AI/ML Resilience & Risk While There's Still Time](https://www.darkreading.com/vulnerabilities-threats/ai-experts-account-ai-ml-resilience-risk-time)

* [Adversarial machine learning and cybersecurity v7 pdf 1](https://fsi9-prod.s3.us-west-1.amazonaws.com/s3fs-public/2023-04/adversarial_machine_learning_and_cybersecurity_v7_pdf_1.pdf)

* [Security Risks of AI](https://www.schneier.com/blog/archives/2023/04/security-risks-of-ai.html)

* [People Are Using A Grandma Exploit To Break AI](https://kotaku.com/chatgpt-ai-discord-clyde-chatbot-exploit-jailbreak-1850352678)

* [The complete artificial intelligence for cyber security 2021](https://www.udemy.com/course/the-complete-artificial-intelligence-for-cyber-security-2021/?utm_source=adwords&utm_medium=udemyads&utm_campaign=DSA_Catchall_la.EN_cc.US&utm_content=deal4584&utm_term=_._ag_95911180068_._ad_532194018662_._kw__._de_c_._dm__._pl__._ti_dsa-841699839303_._li_9018947_._pd__._&matchtype=&gclid=Cj0KCQjwlumhBhClARIsABO6p-ytmFsTOxfnsRJVUapFi2WSP70LuoXBBBy3qw3vKFYxTpwICNPp5fUaAnVlEALw_wcB)

* [Pen testing amid the rise of AI-powered threat actors | TechTarget](https://www.techtarget.com/searchsecurity/post/Pen-testing-amid-the-rise-of-AI-powered-threat-actors)

* [Researcher Tricks ChatGPT Into Building Undetectable Steganography Malware](https://www.darkreading.com/attacks-breaches/researcher-tricks-chatgpt-undetectable-steganography-malware)

* [5 ChatGPT security risks in the enterprise | TechTarget](https://www.techtarget.com/searchsecurity/tip/ChatGPT-security-risks-in-the-enterprise)

* [Feds Call for Certifying, Assessing Veracity of AI Systems](https://www.databreachtoday.com/feds-call-for-certifying-assessing-veracity-ai-systems-a-21661)

* [ChatGPT Already Involved in Data Leaks, Phishing Scams & Malware Infections](https://networkassured.com/security/all-chatgpt-cybersecurity-risks-attacks/)

* [Scammers Use AI To Fake CEO's Voice, Transfer $243,000](https://fossbytes.com/scammers-use-ai-to-fake-ceos-voice-transfer-243000/)

* [Exploiting AI: How Cybercriminals Misuse and Abuse AI and ML](https://www.trendmicro.com/vinfo/us/security/news/cybercrime-and-digital-threats/exploiting-ai-how-cybercriminals-misuse-abuse-ai-and-ml)

* [Deepfake Challenges Will Only Grow](https://www.mccormick.northwestern.edu/news/articles/2023/01/deepfake-challenges-will-only-grow/)

* [Dear enterprise IT: Cybercriminals use AI too](https://venturebeat.com/security/dear-enterprise-it-cybercriminals-use-ai-too/)

* [5 Ways Hackers Will Use ChatGPT For Cyberattacks](https://informationsecuritybuzz.com/5-ways-hackers-will-use-chatgpt-for-cyberattacks/)

* [AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)

* [NATIONAL ARTIFICIAL INTELLIGENCE INITIATIVE](https://www.ai.gov/)

* [Navigating artificial intelligence: Red flags to watch out for](https://www.computerweekly.com/news/366537934/Navigating-artificial-intelligence-Red-flags-to-watch-out-for)

* [Hackers Are Using ChatGPT-Themed Lures to Spread Sophisticated Malware on Meta - CPO Magazine](https://www.cpomagazine.com/cyber-security/hackers-are-using-chatgpt-themed-lures-to-spread-sophisticated-malware-on-meta/?feed_id=93&_unique_id=645a6e63e2a40)

* [Addressing the Security Risks of AI](https://www.lawfareblog.com/addressing-security-risks-ai)

* [Security Implications of ChatGPT | CSA](https://cloudsecurityalliance.org/artifacts/security-implications-of-chatgpt/)

* [Advancements in AI Cybersecurity: Leveraging ChatGPT to Stay Ahead of Cyber Criminals](https://www.cyberdefensemagazine.com/advancements-in-ai-cybersecurity-leveraging-chatgpt-to-stay-ahead-of-cyber-criminals/)

* [Tenable Makes Generative AI Security Tools Available to the Research Community](https://www.tenable.com/press-releases/tenable-makes-generative-ai-security-tools-available-to-the-research-community)

* [ChatGPT and You](https://www.cyberdefensemagazine.com/chatgpt-and-you/)

* [Apple co-founder Warns that AI Could Make Cyber Attacks More Sophisticated](https://cybersecuritynews.com/apple-co-founder-warns/)

* [The Role of Artificial Intelligence in Enhancing Cybersecurity - InApp](https://inapp.com/blog/the-role-of-artificial-intelligence-in-enhancing-cybersecurity/)

* [Finding bugs in AI models at DEF CON 31 - Help Net Security](https://www.helpnetsecurity.com/2023/05/09/finding-bugs-ai-models/)

* [Strengths and Vulnerabilities of AI Applications to Health Care](https://www.cyberdefensemagazine.com/strengths-and-vulnerabilities-of-ai-applications-to-health-care-and-the-protection-of-phi-including-implications-for-the-confidentiality-of-the-doctor-patient-relationship/)

* [LARGE LANGUAGE MODELS CAN BE USED TO EFFECTIVELY SCALE SPEAR PHISHING CAMPAIGNS](https://arxiv.org/ftp/arxiv/papers/2305/2305.06972.pdf)

* [ChatGPT: Friend or Foe? | API Security Newsletter](https://securityboulevard.com/2023/05/chatgpt-friend-or-foe-api-security-newsletter/)

* [OWASP AI Security and Privacy Guide | OWASP Foundation](https://owasp.org/www-project-ai-security-and-privacy-guide/)

* [6 major risks of using ChatGPT, according to a new study](https://www.zdnet.com/article/6-major-risks-of-using-chatgpt-according-to-a-new-study/)

* [10 Types of AI Attacks CISOs Should Track](https://www.darkreading.com/threat-intelligence/10-types-of-ai-attacks-cisos-should-track)

* [Exclusive! Scientists Developed an AI Model that Automatically Links Vulnerabilities With Cyber Attacks](https://cybersecuritynews.com/ai-model-automatically-links-vulnerabilities-with-cyber-attacks/)

* [Exploring the business risks and challenges of chatgpt](https://www.iansresearch.com/resources/all-blogs/post/security-blog/2023/05/23/exploring-the-business-risks-and-challenges-of-chatgpt)

* [Threat Modeling AI/ML Systems and Dependencies - Security documentation](https://learn.microsoft.com/en-us/security/engineering/threat-modeling-aiml)
